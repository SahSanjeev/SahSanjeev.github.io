{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahSanjeev/SahSanjeev.github.io/blob/main/Copy_of_canopy_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5lnwH_kS23q"
      },
      "source": [
        "# TruLens-Canopy Quickstart\n",
        "\n",
        " Canopy is an open-source framework and context engine built on top of the Pinecone vector database so you can build and host your own production-ready chat assistant at any scale. By integrating TruLens into your Canopy assistant, you can quickly iterate on and gain confidence in the quality of your chat assistant.\n",
        "\n",
        " [![Open In\n",
        "Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/frameworks/canopy/canopy_quickstart.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RrjukJ2S23u",
        "outputId": "4266b1d7-3be7-4af3-c7fb-d669f5a8625c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "# !pip install -qU canopy-sdk trulens-eval cohere ipywidgets\n",
        "!pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shc5SagAS23w"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "assert numpy.__version__ >= \"1.26\", \"Numpy version did not updated, if you are working on Colab please restart the session.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyF1LiP4S23w"
      },
      "source": [
        "## Set Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jpmt6JGbS23w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"YOUR_PINECONE_API_KEY\"  # take free trial key from https://app.pinecone.io/\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"  # take free trial key from https://platform.openai.com/api-keys\n",
        "os.environ[\"CO_API_KEY\"] = \"YOUR_COHERE_API_KEY\"  # take free trial key from https://dashboard.cohere.com/api-keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YF5Mvwc7S23x"
      },
      "outputs": [],
      "source": [
        "assert os.environ[\"PINECONE_API_KEY\"] != \"5080754e-5016-45df-80b1-75c103a0ed6a\", \"please provide PINECONE API key\"\n",
        "assert os.environ[\"OPENAI_API_KEY\"] != \"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\", \"please provide OpenAI API key\"\n",
        "assert os.environ[\"CO_API_KEY\"] != \"IRuI3Xiy4jOYeryRZyGRZnVrGJvZKBKKGbQoUb6T\", \"please provide Cohere API key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y_6Cq6iyS23x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c59d5a8-2620-4f1c-8158-d0c6c8ce17a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-3.1.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.0/211.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.10.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Installing collected packages: pinecone-client\n",
            "Successfully installed pinecone-client-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pinecone-client\n",
        "from pinecone import PodSpec\n",
        "\n",
        "# Defines the cloud and region where the index should be deployed\n",
        "# Read more about it here - https://docs.pinecone.io/docs/create-an-index\n",
        "spec = PodSpec(environment=\"gcp-starter\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hFoe-WSS23x"
      },
      "source": [
        "## Load data\n",
        "Downloading Pinecone's documentation as data to ingest to our Canopy chatbot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i3PEvHm_S23x",
        "outputId": "2857b6ed-1770-4758-dd71-3dc25950edae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     id  \\\n",
              "0  728aeea1-1dcf-5d0a-91f2-ecccd4dd4272   \n",
              "1  2f19f269-171f-5556-93f3-a2d7eabbe50f   \n",
              "2  b2a71cb3-5148-5090-86d5-7f4156edd7cf   \n",
              "3  1dafe68a-2e78-57f7-a97a-93e043462196   \n",
              "4  8b07b24d-4ec2-58a1-ac91-c8e6267b9ffd   \n",
              "\n",
              "                                                text  \\\n",
              "0  # Scale indexes\\n\\n[Suggest Edits](/edit/scali...   \n",
              "1  # Understanding organizations\\n\\n[Suggest Edit...   \n",
              "2  # Manage datasets\\n\\n[Suggest Edits](/edit/dat...   \n",
              "3  # Architecture\\n\\n[Suggest Edits](/edit/archit...   \n",
              "4  # Moving to production\\n\\n[Suggest Edits](/edi...   \n",
              "\n",
              "                                              source  \\\n",
              "0      https://docs.pinecone.io/docs/scaling-indexes   \n",
              "1        https://docs.pinecone.io/docs/organizations   \n",
              "2             https://docs.pinecone.io/docs/datasets   \n",
              "3         https://docs.pinecone.io/docs/architecture   \n",
              "4  https://docs.pinecone.io/docs/moving-to-produc...   \n",
              "\n",
              "                                            metadata  \n",
              "0  {'created_at': '2023_10_25', 'title': 'scaling...  \n",
              "1  {'created_at': '2023_10_25', 'title': 'organiz...  \n",
              "2  {'created_at': '2023_10_25', 'title': 'datasets'}  \n",
              "3  {'created_at': '2023_10_25', 'title': 'archite...  \n",
              "4  {'created_at': '2023_10_25', 'title': 'moving-...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c584001d-c23d-4465-8e3f-699ea2e46d85\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>728aeea1-1dcf-5d0a-91f2-ecccd4dd4272</td>\n",
              "      <td># Scale indexes\\n\\n[Suggest Edits](/edit/scali...</td>\n",
              "      <td>https://docs.pinecone.io/docs/scaling-indexes</td>\n",
              "      <td>{'created_at': '2023_10_25', 'title': 'scaling...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2f19f269-171f-5556-93f3-a2d7eabbe50f</td>\n",
              "      <td># Understanding organizations\\n\\n[Suggest Edit...</td>\n",
              "      <td>https://docs.pinecone.io/docs/organizations</td>\n",
              "      <td>{'created_at': '2023_10_25', 'title': 'organiz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b2a71cb3-5148-5090-86d5-7f4156edd7cf</td>\n",
              "      <td># Manage datasets\\n\\n[Suggest Edits](/edit/dat...</td>\n",
              "      <td>https://docs.pinecone.io/docs/datasets</td>\n",
              "      <td>{'created_at': '2023_10_25', 'title': 'datasets'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1dafe68a-2e78-57f7-a97a-93e043462196</td>\n",
              "      <td># Architecture\\n\\n[Suggest Edits](/edit/archit...</td>\n",
              "      <td>https://docs.pinecone.io/docs/architecture</td>\n",
              "      <td>{'created_at': '2023_10_25', 'title': 'archite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8b07b24d-4ec2-58a1-ac91-c8e6267b9ffd</td>\n",
              "      <td># Moving to production\\n\\n[Suggest Edits](/edi...</td>\n",
              "      <td>https://docs.pinecone.io/docs/moving-to-produc...</td>\n",
              "      <td>{'created_at': '2023_10_25', 'title': 'moving-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c584001d-c23d-4465-8e3f-699ea2e46d85')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c584001d-c23d-4465-8e3f-699ea2e46d85 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c584001d-c23d-4465-8e3f-699ea2e46d85');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8e94a04-741d-46d5-885d-f19676e6b170\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8e94a04-741d-46d5-885d-f19676e6b170')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8e94a04-741d-46d5-885d-f19676e6b170 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 60,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"728aeea1-1dcf-5d0a-91f2-ecccd4dd4272\",\n          \"06609e7b-6caa-5c83-a185-5e165621e44c\",\n          \"085c267b-eaae-5dc7-9d16-21073755d9a5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"# Scale indexes\\n\\n[Suggest Edits](/edit/scaling-indexes)In this topic, we explain how you can scale your indexes horizontally and vertically.\\n\\n\\nProjects in the `gcp-starter` environment do not support the features referred to here, including pods, replicas, and collections.\\n\\n\\n## Vertical vs. horizontal scaling\\n\\n\\nIf you need to scale your environment to accommodate more vectors, you can modify your existing index to scale it vertically or create a new index and scale horizontally. This article will describe both methods and how to scale your index effectively. \\n\\n\\n## Vertical scaling\\n\\n\\nScaling vertically is fast and involves no downtime. This is a good choice when you can't pause upserts and must continue serving traffic. It also allows you to double your capacity instantly. However, there are some factors to consider.\\n\\n\\nBy [changing the pod size](manage-indexes#changing-pod-sizes), you can scale to x2, x4, and x8 pod sizes, which means you are doubling your capacity at each step. Moving up to a new capacity will effectively double the number of pods used at each step. If you need to scale by smaller increments, then consider horizontal scaling. \\n\\n\\nThe number of base pods you specify when you initially create the index is static and cannot be changed. For example, if you start with 10 pods of `p1.x1` and vertically scale to `p1.x2`, this equates to 20 pods worth of usage. Neither can you change pod types with vertical scaling. If you want to change your pod type while scaling, then horizontal scaling is the better option. \\n\\n\\nYou can only scale index sizes up and cannot scale them back down.\\n\\n\\nSee our learning center for more information on [vertical scaling](https://www.pinecone.io/learn/testing-p2-collections-scaling/#vertical-scaling-on-p1-and-s1).\\n\\n\\n## Horizontal scaling\\n\\n\\nThere are two approaches to horizontal scaling in Pinecone: adding pods and adding replicas. Adding pods increases all resources but requires a pause in upserts; adding replicas only increases throughput and requires no pause in upserts.\\n\\n\\n### Adding pods\\n\\n\\nAdding pods to an index increases all resources, including available capacity. Adding pods to an existing index is possible using our <collections> feature. A collection is an immutable snapshot of your index in time: a collection stores the data but not the original index definition.\\n\\n\\nWhen you [create an index from a collection](manage-indexes#create-an-index-from-a-collection), you define the new index configuration. This allows you to scale the base pod count horizontally without scaling vertically. The main advantage of this approach is that you can scale incrementally instead of doubling capacity as with vertical scaling. Also, you can redefine pod types if you are experimenting or if you need to use a different pod type, such asperformance-optimized pods or storage-optimized pods. Another advantage of this method is that you can change your [metadata configuration](manage-indexes#selective-metadata-indexing) to redefine metadata fields as indexed or stored-only. This is important when [tuning your index](performance-tuning) for the best throughput. \\n\\n\\nHere are the general steps to make a copy of your index and create a new index while changing the pod type, pod count, metadata configuration, replicas, and all typical parameters when creating a new collection: \\n\\n\\n1. Pause upserts.\\n2. Create a collection from the current index.\\n3. Create an index from the collection with new parameters.\\n4. Continue upserts to the newly created index. Note: the URL has likely changed.\\n5. Delete the old index if desired.\\n\\n\\n### Adding replicas\\n\\n\\nEach replica duplicates the resources and data in an index. This means that adding additional replicas increases the throughput of the index but not its capacity. However, adding replicas does not require downtime.\\n\\n\\nThroughput in terms of queries per second (QPS) scales linearly with the number of replicas per index.\\n\\n\\nTo add replicas, use the `configure_index` operation to [increase the number of replicas for your index](manage-indexes#replicas).\\n\\n\\n## Next steps\\n\\n\\n* See our learning center for more information on [vertical scaling](https://www.pinecone.io/learn/testing-p2-collections-scaling/#vertical-scaling-on-p1-and-s1).\\n* Learn more about <collections>.\\nUpdated 29 days ago \\n\\n\\n\\n---\\n\\n* [Table of Contents](#)\\n* + [Vertical vs. horizontal scaling](#vertical-vs-horizontal-scaling)\\n\\t+ [Vertical scaling](#vertical-scaling)\\n\\t+ [Horizontal scaling](#horizontal-scaling)\\n\\t\\t- [Adding pods](#adding-pods)\\n\\t\\t- [Adding replicas](#adding-replicas)\\n\\t+ [Next steps](#next-steps)\\n\",\n          \"# Understanding projects\\n\\n[Suggest Edits](/edit/projects)## Overview\\n\\n\\nThis document explains the concepts related to Pinecone projects.\\n\\n\\n## Projects contain indexes and users\\n\\n\\nEach Pinecone project contains a number of [indexes](/docs/indexes) and users. Only a user who belongs to the project can access the indexes in that project. Each project also has at least one project owner. All of the pods in a single project are located in a single environment. \\n\\n\\n## Project settings\\n\\n\\nWhen you create a new project, you can choose the **name**, **deployment environment**, and **pod limit**.\\n\\n\\n### Project environment\\n\\n\\nWhen creating a project, you must choose a cloud environment for the indexes in that project. Your project environment can affect your [pricing](https://pinecone.io/pricing). The following table lists the available cloud regions, the corresponding values of the `environment` parameter for the [init() operation](quickstart#2-get-and-verify-your-pinecone-api-key), and which billing tier has access to each environment:\\n\\n\\n\\n\\n| Cloud region | `environment` value | Tier availability |\\n| --- | --- | --- |\\n| GCP Starter (Iowa)\\\\* | gcp-starter | Starter |\\n| GCP US-West-1 Free (N. California) | us-west1-gcp-free | Starter |\\n| GCP Asia-Southeast-1 (Singapore) | asia-southeast1-gcp-free | Starter |\\n| GCP US-West-4 (Las Vegas) | us-west4-gcp-free | Starter |\\n| GCP US-West-1 (N. California) | us-west1-gcp | Standard / Enterprise |\\n| GCP US-Central-1 (Iowa) | us-central1-gcp | Standard / Enterprise |\\n| GCP US-West-4 (Las Vegas) | us-west4-gcp | Standard / Enterprise |\\n| GCP US-East-4 (Virginia) | us-east4-gcp | Standard / Enterprise |\\n| GCP northamerica-northeast-1 | northamerica-northeast1-gcp | Standard / Enterprise |\\n| GCP Asia-Northeast-1 (Japan) | asia-northeast1-gcp | Standard / Enterprise |\\n| GCP Asia-Southeast-1 (Singapore) | asia-southeast1-gcp | Standard / Enterprise |\\n| GCP US-East-1 (South Carolina) | us-east1-gcp | Standard / Enterprise |\\n| GCP EU-West-1 (Belgium) | eu-west1-gcp | Standard / Enterprise |\\n| GCP EU-West-4 (Netherlands) | eu-west4-gcp | Standard / Enterprise |\\n| AWS US-East-1 (Virginia) | us-east-1-aws | Standard / Enterprise |\\n| Azure East US (Virginia) | eastus-azure | Standard / Enterprise |\\n\\n\\n\\\\* This environment has unique features and limitations. See [`gcp-starter` environment](starter-environment) for more information.\\n\\n\\n [Contact us](http://www.pinecone.io/contact/) if you need a dedicated deployment in other regions.\\n\\n\\nThe environment cannot be changed after the project is created.\\n\\n\\n### Project pod limit\\n\\n\\nYou can set the maximum number of pods that can be used in total across all indexes in a project. Use this to control costs.\\n\\n\\nThe pod limit can be changed only by the project owner.\\n\\n\\n### Project roles\\n\\n\\nThere are two project roles: **Project owner** and **project member.** Table 1 below summarizes the permissions for each role.\\n\\n\\n**Table 1: Project roles and permissions**\\n\\n\\n\\n\\n| Project role | Permissions in organization |\\n| --- | --- |\\n| Project owner | Manage project members |\\n|  | Manage project API keys |\\n|  | Manage pod limits |\\n| Project member | Access API keys |\\n|  | Create indexes in project |\\n|  | Use indexes in project |\\n\\n\\n## API keys\\n\\n\\nEach Pinecone [project](projects) has one or more API keys. In order to [make calls to the Pinecone API](quickstart), a user must provide a valid API key for the relevant Pinecone project.\\n\\n\\nTo view the API key for your project, open the [Pinecone console](https://app.pinecone.io), select the project, and click **API Keys**.\\n\\n\\n## Project ID\\n\\n\\nEach Pinecone project has a project ID. This hexadecimal string appears as part of the URL for API calls. \\n\\n\\nTo find a project's ID, follow these steps:\\n\\n\\n1. Go to the [Pinecone console](https://app.pinecone.io).\\n2. In the upper-left corner, select your project.\\n3. Click **Indexes**.\\n4. Under the name of your indexes, find the index URL. For example:\\n\\n\\n`example-index-1e3g52e.svc.us-east1-gcp.pinecone.io`\\n\\n\\nThe portion of the index URL after the index name and before the dot is the project ID. \\n\\n\\nFor example, in the index URL `test-index-3e2f43f.svc.us-east1-gcp.pinecone.io`, the project ID is `3e2f43f`.\\n\\nUpdated 29 days ago \\n\\n\\n\\n---\\n\\n* [Table of Contents](#)\\n* + [Overview](#overview)\\n\\t+ [Projects contain indexes and users](#projects-contain-indexes-and-users)\\n\\t+ [Project settings](#project-settings)\\n\\t\\t- [Project environment](#project-environment)\\n\\t\\t- [Project pod limit](#project-pod-limit)\\n\\t\\t- [Project roles](#project-roles)\\n\\t+ [API keys](#api-keys)\\n\\t+ [Project ID](#project-id)\\n\",\n          \"# Monitoring your usage\\n\\n[Suggest Edits](/edit/monitoring-usage)This document describes how to monitor the usage and costs for your Pinecone organization through the Pinecone console.\\n\\n\\nTo view your Pinecone usage, you must be the [organization owner](organizations#organization-owners) for your organization. This feature is only available to organizations on the Standard or Enterprise plans.\\n\\n\\nTo view your usage through the Pinecone console, follow these steps:\\n\\n\\n1. Log in to the [Pinecone console](https://app.pinecone.io).\\n2. In the left menu, click **Organizations**.\\n3. Click the **USAGE** tab.\\n\\n\\nAll dates are given in UTC to match billing invoices.\\n\\nUpdated 29 days ago \\n\\n\\n\\n---\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"https://docs.pinecone.io/docs/scaling-indexes\",\n          \"https://docs.pinecone.io/docs/projects\",\n          \"https://docs.pinecone.io/docs/monitoring-usage\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "data = pd.read_parquet(\"https://storage.googleapis.com/pinecone-datasets-dev/pinecone_docs_ada-002/raw/file1.parquet\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n6OKiIFiS23z",
        "outputId": "6ac6df42-28e2-4233-e419-71c49ee257e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Limits\n",
            "This is a summary of current Pinecone limitations. For many of these, there is a workaround or we're working on increasing the limits.\n",
            "\n",
            "## Upserts\n",
            "\n",
            "Max vector dimensionality is 20,000.\n",
            "\n",
            "Max size for an upsert request is 2MB. Recommended upsert limit is 100 vectors per request.\n",
            "\n",
            "Vectors may not be visible to queries immediately after upserting. You can check if the vectors were indexed by looking at the total with `describe_index_stats()`, although this method may not work if the index has multiple replicas. Pinecone is eventually consistent.\n",
            "\n",
            "Pinecone supports sparse vector values of sizes up to 1000 non-zero values.\n",
            "\n",
            "## Queries\n",
            "\n",
            "Max value for `top_k`, the number of results to return, is 10,000. Max value for `top_k` for queries with `include_metadata=True` or `include_data=True` is 1,000.\n",
            "\n",
            "......\n",
            "source:  https://docs.pinecone.io/docs/limits\n"
          ]
        }
      ],
      "source": [
        "print(data[\"text\"][50][:847].replace(\"\\n\\n\", \"\\n\").replace(\"[Suggest Edits](/edit/limits)\", \"\") + \"\\n......\")\n",
        "print(\"source: \", data[\"source\"][50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDottlBVS23z"
      },
      "source": [
        "## Setup Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xS_CFdPPS230",
        "outputId": "e3da4a88-58a2-4bd9-b19d-c9b089771532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: canopy in /usr/local/lib/python3.10/dist-packages (8.42)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from canopy) (1.25.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from canopy) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from canopy) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from canopy) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.23 in /usr/local/lib/python3.10/dist-packages (from canopy) (2.0.7)\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from canopy) (1.5.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from canopy) (3.9.3)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from canopy) (4.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.1->canopy) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->canopy) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->canopy) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->canopy) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->canopy) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->canopy) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->canopy) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp->canopy) (3.6)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'canopy.tokenizer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-67a2d228f892>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install canopy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcanopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'canopy.tokenizer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install canopy\n",
        "from canopy.tokenizer import Tokenizer\n",
        "Tokenizer.initialize()\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.tokenize(\"Hello world!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzJnYwU6S230"
      },
      "source": [
        "## Create and Load Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5cVpPuSS231",
        "outputId": "bbe9312a-4bb8-4131-8858-e43e20882906",
        "colab": {
          "referenced_widgets": [
            "e9a6d6b172f14794a03956a0dcf55b61"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9a6d6b172f14794a03956a0dcf55b61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from canopy.knowledge_base import KnowledgeBase\n",
        "from canopy.models.data_models import Document\n",
        "from canopy.knowledge_base import list_canopy_indexes\n",
        "\n",
        "index_name = \"pinecone-docs\"\n",
        "\n",
        "kb = KnowledgeBase(index_name)\n",
        "\n",
        "if not any(name.endswith(index_name) for name in list_canopy_indexes()):\n",
        "    kb.create_canopy_index(spec=spec)\n",
        "\n",
        "kb.connect()\n",
        "\n",
        "documents = [Document(**row) for _, row in data.iterrows()]\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "for i in tqdm(range(0, len(documents), batch_size)):\n",
        "    kb.upsert(documents[i: i+batch_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG81hLs-S232"
      },
      "source": [
        "## Create context and chat engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO_V3fHZS232"
      },
      "outputs": [],
      "source": [
        "from canopy.models.data_models import Query\n",
        "from canopy.context_engine import ContextEngine\n",
        "context_engine = ContextEngine(kb)\n",
        "\n",
        "from canopy.chat_engine import ChatEngine\n",
        "chat_engine = ChatEngine(context_engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnaKnPVeS233"
      },
      "source": [
        "API for chat is exactly the same as for OpenAI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1prnv2k1S233",
        "outputId": "658f7963-0c75-4153-9e18-3dcb74f75d9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The maximum value for `top_k` in a Pinecone query is 10,000. However, when the query includes metadata or data, the maximum value for `top_k` is limited to 1,000.\\n(Source: https://docs.pinecone.io/docs/limits)'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from canopy.models.data_models import UserMessage\n",
        "\n",
        "chat_history = [UserMessage(content=\"What is the the maximum top-k for a query to Pinecone?\")]\n",
        "\n",
        "chat_engine.chat(chat_history).choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WBKbmojS233"
      },
      "source": [
        "## Instrument static methods used by engine with TruLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvFbAcHUS233"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "from trulens_eval.tru_custom_app import instrument\n",
        "\n",
        "from canopy.context_engine import ContextEngine\n",
        "instrument.method(ContextEngine, \"query\")\n",
        "\n",
        "from canopy.chat_engine import ChatEngine\n",
        "instrument.method(ChatEngine, \"chat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpPJ3V_2S233"
      },
      "source": [
        "## Create feedback functions using instrumented methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VT_fk9MS234",
        "outputId": "df04de0e-c5cc-4181-f569-272b5db04b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
            "ðŸ”’ Secret keys will not be included in the database.\n"
          ]
        }
      ],
      "source": [
        "from trulens_eval import Tru\n",
        "tru = Tru(database_redact_keys=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G16wyR-KS234",
        "outputId": "e27f3cdd-c163-4191-958c-1b87d01e7b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… In Groundedness, input source will be set to __record__.app.context_engine.query.rets.content.root[:].snippets[:].text.collect() .\n",
            "âœ… In Groundedness, input statement will be set to __record__.app.chat.rets.choices[0].message.content .\n",
            "âœ… In Answer Relevance, input prompt will be set to __record__.app.chat.args.messages[0].content .\n",
            "âœ… In Answer Relevance, input response will be set to __record__.app.chat.rets.choices[0].message.content .\n",
            "âœ… In Context Relevance, input question will be set to __record__.app.chat.args.messages[0].content .\n",
            "âœ… In Context Relevance, input statement will be set to __record__.app.context_engine.query.rets.content.root[:].snippets[:].text .\n"
          ]
        }
      ],
      "source": [
        "from trulens_eval import Feedback, Select\n",
        "from trulens_eval.feedback import Groundedness\n",
        "from trulens_eval.feedback.provider.openai import OpenAI as fOpenAI\n",
        "import numpy as np\n",
        "\n",
        "# Initialize provider class\n",
        "fopenai = fOpenAI()\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=fopenai)\n",
        "\n",
        "intput = Select.RecordCalls.chat.args.messages[0].content\n",
        "context = Select.RecordCalls.context_engine.query.rets.content.root[:].snippets[:].text\n",
        "output = Select.RecordCalls.chat.rets.choices[0].message.content\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\", higher_is_better=True)\n",
        "    .on(context.collect())\n",
        "    .on(output)\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_qa_relevance = (\n",
        "    Feedback(fopenai.relevance_with_cot_reasons, name = \"Answer Relevance\", higher_is_better=True)\n",
        "    .on(intput)\n",
        "    .on(output)\n",
        ")\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_context_relevance = (\n",
        "    Feedback(fopenai.qs_relevance_with_cot_reasons, name = \"Context Relevance\", higher_is_better=True)\n",
        "    .on(intput)\n",
        "    .on(context)\n",
        "    .aggregate(np.mean)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gOcDPhrS234"
      },
      "source": [
        "## Create recorded app and run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI3kI3W7S234"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "\n",
        "app_id = \"canopy default\"\n",
        "tru_recorder = TruCustomApp(chat_engine, app_id=app_id, feedbacks = [f_groundedness, f_qa_relevance, f_context_relevance])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8Ml8V-9S235"
      },
      "outputs": [],
      "source": [
        "from canopy.models.data_models import UserMessage\n",
        "\n",
        "queries = [\n",
        "    [UserMessage(content=\"What is the maximum dimension for a dense vector in Pinecone?\")],\n",
        "    [UserMessage(content=\"How can you get started with Pinecone and TruLens?\")],\n",
        "    [UserMessage(content=\"What is the the maximum top-k for a query to Pinecone?\")]\n",
        "]\n",
        "\n",
        "answers = []\n",
        "\n",
        "for query in queries:\n",
        "    with tru_recorder as recording:\n",
        "        response = chat_engine.chat(query)\n",
        "        answers.append(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhQUUOj_S235"
      },
      "source": [
        "As you can see, we got the wrong answer, the limits for sparse vectors instead of dense vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77J6RdrvS235",
        "outputId": "345aea24-a344-4ea0-e6ad-1861481a90a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the maximum dimension for a dense vector in Pinecone?\n",
            "\n",
            "The maximum dimension for a dense vector in Pinecone is 4 billion dimensions.\n"
          ]
        }
      ],
      "source": [
        "print(queries[0][0].content + \"\\n\")\n",
        "print(answers[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWacwzJbS235",
        "outputId": "dbaec943-b218-4a55-a31d-baf81f56c6f2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Groundedness</th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>canopy default</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.769524</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>0.002687</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Groundedness  Context Relevance  Answer Relevance   latency   \n",
              "app_id                                                                        \n",
              "canopy default      0.333333           0.769524          0.966667  3.333333  \\\n",
              "\n",
              "                total_cost  \n",
              "app_id                      \n",
              "canopy default    0.002687  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tru.get_leaderboard(app_ids=[app_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHYsHciJS235"
      },
      "source": [
        "## Run Canopy with Cohere reranker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzkGzN8tS236"
      },
      "outputs": [],
      "source": [
        "from canopy.knowledge_base.reranker.cohere import CohereReranker\n",
        "\n",
        "kb = KnowledgeBase(index_name=index_name, reranker=CohereReranker(top_n=3), default_top_k=30)\n",
        "kb.connect()\n",
        "\n",
        "reranker_chat_engine = ChatEngine(ContextEngine(kb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ9-uWR5S236"
      },
      "outputs": [],
      "source": [
        "reranking_app_id = \"canopy_reranking\"\n",
        "reranking_tru_recorder = TruCustomApp(reranker_chat_engine,\n",
        "                                      app_id=reranking_app_id,\n",
        "                                      feedbacks = [f_groundedness, f_qa_relevance, f_context_relevance])\n",
        "\n",
        "answers = []\n",
        "\n",
        "for query in queries:\n",
        "    with reranking_tru_recorder as recording:\n",
        "        answers.append(reranker_chat_engine.chat(query).choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yki3DIt8S236"
      },
      "source": [
        "With reranking we get the right answer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HouG9XzoS236",
        "outputId": "ff89350b-12c5-4eae-f597-25e74c8e58cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the maximum dimension for a dense vector in Pinecone?\n",
            "\n",
            "The maximum dimension for a dense vector in Pinecone is 20,000. (Source: https://docs.pinecone.io/docs/limits)\n"
          ]
        }
      ],
      "source": [
        "print(queries[0][0].content + \"\\n\")\n",
        "print(answers[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN7l1cKyS237"
      },
      "source": [
        "## Evaluate the effect of reranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nylulULzS237",
        "outputId": "24760112-fd86-49b0-9141-478c037bb9d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Groundedness</th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>canopy_reranking</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>0.002118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>canopy default</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.764286</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>0.002687</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Groundedness  Context Relevance  Answer Relevance   latency   \n",
              "app_id                                                                          \n",
              "canopy_reranking      0.833333           0.775000          0.900000  3.333333  \\\n",
              "canopy default        0.333333           0.764286          0.966667  3.333333   \n",
              "\n",
              "                  total_cost  \n",
              "app_id                        \n",
              "canopy_reranking    0.002118  \n",
              "canopy default      0.002687  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tru.get_leaderboard(app_ids=[app_id, reranking_app_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwM4zayBS237"
      },
      "source": [
        "## Explore more in the TruLens dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3yRjXxKS237",
        "outputId": "4ae86131-4dab-4f7d-c7f1-3e90a954a6bb",
        "colab": {
          "referenced_widgets": [
            "ca0ed9f4b500407198db88d8920a0d1a"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting dashboard ...\n",
            "Config file already exists. Skipping writing process.\n",
            "Credentials file already exists. Skipping writing process.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca0ed9f4b500407198db88d8920a0d1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dashboard started at http://192.168.1.157:8501 .\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tru.run_dashboard()\n",
        "\n",
        "# tru.stop_dashboard() # stop if needed"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "b49ef6d0b3ca0fd6117ebbca48c3d697c422d5d25bd8bdbbbbafb3db0f51ca63"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}