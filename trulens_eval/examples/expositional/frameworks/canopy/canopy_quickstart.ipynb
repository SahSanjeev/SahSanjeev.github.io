{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahSanjeev/SahSanjeev.github.io/blob/main/trulens_eval/examples/expositional/frameworks/canopy/canopy_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPzUvjqSB0Im"
      },
      "source": [
        "# TruLens-Canopy Quickstart\n",
        "\n",
        " Canopy is an open-source framework and context engine built on top of the Pinecone vector database so you can build and host your own production-ready chat assistant at any scale. By integrating TruLens into your Canopy assistant, you can quickly iterate on and gain confidence in the quality of your chat assistant.\n",
        "\n",
        " [![Open In\n",
        "Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/frameworks/canopy/canopy_quickstart.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HHt8ZjgZB0Ip"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU canopy-sdk trulens-eval cohere ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h4ry4yRiB0Ir",
        "outputId": "069d4c3a-9e17-4d80-9e7d-50f5fd298550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "Successfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Numpy version did not updated, if you are working on Colab please restart the session.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d9e94123d359>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install --upgrade numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m\"1.26\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Numpy version did not updated, if you are working on Colab please restart the session.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: Numpy version did not updated, if you are working on Colab please restart the session."
          ]
        }
      ],
      "source": [
        "!pip install --upgrade numpy\n",
        "import numpy\n",
        "assert numpy.__version__ >= \"1.26\", \"Numpy version did not updated, if you are working on Colab please restart the session.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVYiGJsQB0Ir"
      },
      "source": [
        "## Set Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjXbzhJYB0Ir"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"YOUR_PINECONE_API_KEY\"  # take free trial key from https://app.pinecone.io/\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"  # take free trial key from https://platform.openai.com/api-keys\n",
        "os.environ[\"CO_API_KEY\"] = \"YOUR_COHERE_API_KEY\"  # take free trial key from https://dashboard.cohere.com/api-keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipjpAu7aB0Is"
      },
      "outputs": [],
      "source": [
        "assert os.environ[\"PINECONE_API_KEY\"] != \"YOUR_PINECONE_API_KEY\", \"please provide PINECONE API key\"\n",
        "assert os.environ[\"OPENAI_API_KEY\"] != \"YOUR_OPENAI_API_KEY\", \"please provide OpenAI API key\"\n",
        "assert os.environ[\"CO_API_KEY\"] != \"YOUR_COHERE_API_KEY\", \"please provide Cohere API key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg2e4junB0Is"
      },
      "outputs": [],
      "source": [
        "from pinecone import PodSpec\n",
        "\n",
        "# Defines the cloud and region where the index should be deployed\n",
        "# Read more about it here - https://docs.pinecone.io/docs/create-an-index\n",
        "spec = PodSpec(environment=\"gcp-starter\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqTO96AiB0Is"
      },
      "source": [
        "## Load data\n",
        "Downloading Pinecone's documentation as data to ingest to our Canopy chatbot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op172eD3B0Is"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "data = pd.read_parquet(\"https://storage.googleapis.com/pinecone-datasets-dev/pinecone_docs_ada-002/raw/file1.parquet\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpIuifPrB0Iu"
      },
      "outputs": [],
      "source": [
        "print(data[\"text\"][50][:847].replace(\"\\n\\n\", \"\\n\").replace(\"[Suggest Edits](/edit/limits)\", \"\") + \"\\n......\")\n",
        "print(\"source: \", data[\"source\"][50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsIN-7dgB0Iv"
      },
      "source": [
        "## Setup Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-6CFn7SB0Iv"
      },
      "outputs": [],
      "source": [
        "from canopy.tokenizer import Tokenizer\n",
        "Tokenizer.initialize()\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.tokenize(\"Hello world!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E6JD03vB0Iw"
      },
      "source": [
        "## Create and Load Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ho_0IReB0Iw"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from canopy.knowledge_base import KnowledgeBase\n",
        "from canopy.models.data_models import Document\n",
        "from canopy.knowledge_base import list_canopy_indexes\n",
        "\n",
        "index_name = \"pinecone-docs\"\n",
        "\n",
        "kb = KnowledgeBase(index_name)\n",
        "\n",
        "if not any(name.endswith(index_name) for name in list_canopy_indexes()):\n",
        "    kb.create_canopy_index(spec=spec)\n",
        "\n",
        "kb.connect()\n",
        "\n",
        "documents = [Document(**row) for _, row in data.iterrows()]\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "for i in tqdm(range(0, len(documents), batch_size)):\n",
        "    kb.upsert(documents[i: i+batch_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I5QQv6wB0Ix"
      },
      "source": [
        "## Create context and chat engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "troz33ELB0Ix"
      },
      "outputs": [],
      "source": [
        "from canopy.models.data_models import Query\n",
        "from canopy.context_engine import ContextEngine\n",
        "context_engine = ContextEngine(kb)\n",
        "\n",
        "from canopy.chat_engine import ChatEngine\n",
        "chat_engine = ChatEngine(context_engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fEXyKhDB0Ix"
      },
      "source": [
        "API for chat is exactly the same as for OpenAI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXhs3wMSB0Ix"
      },
      "outputs": [],
      "source": [
        "from canopy.models.data_models import UserMessage\n",
        "\n",
        "chat_history = [UserMessage(content=\"What is the the maximum top-k for a query to Pinecone?\")]\n",
        "\n",
        "chat_engine.chat(chat_history).choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMb-xnWEB0Iy"
      },
      "source": [
        "## Instrument static methods used by engine with TruLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tmWfE5VkB0Iy",
        "outputId": "88d8fa9d-eaa7-49e4-8189-14792aa4e7ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'warnings' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-98f7cada1e9a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrulens_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtru_custom_app\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minstrument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcanopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_engine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContextEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minstrument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mContextEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"query\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'warnings' is not defined"
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "from trulens_eval.tru_custom_app import instrument\n",
        "\n",
        "from canopy.context_engine import ContextEngine\n",
        "instrument.method(ContextEngine, \"query\")\n",
        "\n",
        "from canopy.chat_engine import ChatEngine\n",
        "instrument.method(ChatEngine, \"chat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oiPnvPBB0I3"
      },
      "source": [
        "## Create feedback functions using instrumented methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lx5vy9dB0I4"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import Tru\n",
        "tru = Tru(database_redact_keys=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e4qcnO9B0I4"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import Feedback, Select\n",
        "from trulens_eval.feedback import Groundedness\n",
        "from trulens_eval.feedback.provider.openai import OpenAI as fOpenAI\n",
        "import numpy as np\n",
        "\n",
        "# Initialize provider class\n",
        "fopenai = fOpenAI()\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=fopenai)\n",
        "\n",
        "intput = Select.RecordCalls.chat.args.messages[0].content\n",
        "context = Select.RecordCalls.context_engine.query.rets.content.root[:].snippets[:].text\n",
        "output = Select.RecordCalls.chat.rets.choices[0].message.content\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\", higher_is_better=True)\n",
        "    .on(context.collect())\n",
        "    .on(output)\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_qa_relevance = (\n",
        "    Feedback(fopenai.relevance_with_cot_reasons, name = \"Answer Relevance\", higher_is_better=True)\n",
        "    .on(intput)\n",
        "    .on(output)\n",
        ")\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_context_relevance = (\n",
        "    Feedback(fopenai.qs_relevance_with_cot_reasons, name = \"Context Relevance\", higher_is_better=True)\n",
        "    .on(intput)\n",
        "    .on(context)\n",
        "    .aggregate(np.mean)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCrZH1P7B0I4"
      },
      "source": [
        "## Create recorded app and run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymccqBkVB0I4"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "\n",
        "app_id = \"canopy default\"\n",
        "tru_recorder = TruCustomApp(chat_engine, app_id=app_id, feedbacks = [f_groundedness, f_qa_relevance, f_context_relevance])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-LQ_BeYB0I4"
      },
      "outputs": [],
      "source": [
        "from canopy.models.data_models import UserMessage\n",
        "\n",
        "queries = [\n",
        "    [UserMessage(content=\"What is the maximum dimension for a dense vector in Pinecone?\")],\n",
        "    [UserMessage(content=\"How can you get started with Pinecone and TruLens?\")],\n",
        "    [UserMessage(content=\"What is the the maximum top-k for a query to Pinecone?\")]\n",
        "]\n",
        "\n",
        "answers = []\n",
        "\n",
        "for query in queries:\n",
        "    with tru_recorder as recording:\n",
        "        response = chat_engine.chat(query)\n",
        "        answers.append(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMr0H2yTB0I5"
      },
      "source": [
        "As you can see, we got the wrong answer, the limits for sparse vectors instead of dense vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dpfp3khB0I5"
      },
      "outputs": [],
      "source": [
        "print(queries[0][0].content + \"\\n\")\n",
        "print(answers[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbwY6YhEB0I6"
      },
      "outputs": [],
      "source": [
        "tru.get_leaderboard(app_ids=[app_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afAPeoxnB0I6"
      },
      "source": [
        "## Run Canopy with Cohere reranker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EKOK3bWB0I6"
      },
      "outputs": [],
      "source": [
        "from canopy.knowledge_base.reranker.cohere import CohereReranker\n",
        "\n",
        "kb = KnowledgeBase(index_name=index_name, reranker=CohereReranker(top_n=3), default_top_k=30)\n",
        "kb.connect()\n",
        "\n",
        "reranker_chat_engine = ChatEngine(ContextEngine(kb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVbK1bt0B0I6"
      },
      "outputs": [],
      "source": [
        "reranking_app_id = \"canopy_reranking\"\n",
        "reranking_tru_recorder = TruCustomApp(reranker_chat_engine,\n",
        "                                      app_id=reranking_app_id,\n",
        "                                      feedbacks = [f_groundedness, f_qa_relevance, f_context_relevance])\n",
        "\n",
        "answers = []\n",
        "\n",
        "for query in queries:\n",
        "    with reranking_tru_recorder as recording:\n",
        "        answers.append(reranker_chat_engine.chat(query).choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkl_WJXgB0I7"
      },
      "source": [
        "With reranking we get the right answer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuLOf6AIB0I7"
      },
      "outputs": [],
      "source": [
        "print(queries[0][0].content + \"\\n\")\n",
        "print(answers[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4b09MnpB0I7"
      },
      "source": [
        "## Evaluate the effect of reranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf3EwOHNB0I7"
      },
      "outputs": [],
      "source": [
        "tru.get_leaderboard(app_ids=[app_id, reranking_app_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77_EJpgLB0I8"
      },
      "source": [
        "## Explore more in the TruLens dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc24RDkmB0I8"
      },
      "outputs": [],
      "source": [
        "tru.run_dashboard()\n",
        "\n",
        "# tru.stop_dashboard() # stop if needed"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "b49ef6d0b3ca0fd6117ebbca48c3d697c422d5d25bd8bdbbbbafb3db0f51ca63"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}